{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Link: https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context\n",
    "\n",
    "It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "\n",
    "Content\n",
    "\n",
    "The dataset contains transactions made by credit cards in September 2013 by European cardholders. \n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.48.0 to work with Novchan_ML\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'credit dataset' not in ws.datasets:\n",
    "    ## first upload the files\n",
    "    default_ds.upload_files(files=['./creditcard.csv'], # Upload the csv files in /data\n",
    "                        target_path='Fraud_Detection/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "    \n",
    "        #Then Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'Fraud_Detection/*.csv'))\n",
    "\n",
    "    # Then Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='credit dataset',\n",
    "                                description='For Credit Card Fraud Detection',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit_card_fraud_detection_on_azure folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'Credit_card_fraud_detection_on_azure'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Credit_card_fraud_detection_on_azure/fraud_detection_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/fraud_detection_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,precision_score\n",
    "\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=1, help='regularization rate')\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "reg = args.reg_rate ## set reg based on what we input in ScriptRunConfig argument parameter\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "fraud_detection = run.input_datasets['training_data'].to_pandas_dataframe() ##<-recall, select datasets using name instead of id (see 06)\n",
    "\n",
    "#split data into training set and test set\n",
    "X = fraud_detection.iloc[:, 1:-2]\n",
    "y = fraud_detection.iloc[:, -1]\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate precision\n",
    "y_hat = model.predict(X_test)\n",
    "precision = precision_score(y_test,y_hat)\n",
    "print('Precision:', precision)\n",
    "run.log('Precision', np.float(precision))\n",
    "\n",
    "## Plot the imbalanced data\n",
    "fig = plt.figure(figsize=(12,7)) ## seems it cant change the size of the FacetGrid\n",
    "#sns.catplot(data=fraud_detection,x='Class',kind='count',log=True) ##<-for unknown reason, azure cannot log FacetGrid (shows blank)\n",
    "sns.countplot(data=fraud_detection,x='Class',log=True)\n",
    "# g.fig.suptitle(\"Class Imbalance\",y=1.05,fontsize=15,horizontalalignment='right') #<-also works!\n",
    "plt.title(\"Test\",y=1.05,fontsize=15,loc='left')\n",
    "plt.xticks([0,1],['False','True'],size=20)\n",
    "plt.xlabel(xlabel='CLASS',size=20) #<-xlabel arg is required\n",
    "run.log_image(name=\"Imbalanced_data\",plot=fig)\n",
    "plt.show()\n",
    "\n",
    "os.makedirs('outputs',exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/fraud_detection_model.pkl') ##<-recall, as this py is run on cloud, you can see this file in the outputs tab in Studio\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Credit_card_fraud_detection_on_azure/fraud_detection_training_w_SMOTE.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/fraud_detection_training_w_SMOTE.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=1, help='regularization rate')\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "reg = args.reg_rate ## set reg based on what we input in ScriptRunConfig argument parameter\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "fraud_detection = run.input_datasets['training_data'].to_pandas_dataframe() ##<-recall, select datasets using name instead of id (see 06)\n",
    "\n",
    "#split data into training set and test set\n",
    "X = fraud_detection.iloc[:, 1:-2]\n",
    "y = fraud_detection.iloc[:, -1]\n",
    "\n",
    "#instantiate SMOTE and transform into balanced dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X_bal,y_bal = sm.fit_resample(X,y)\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, \n",
    "                                                    test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate precision\n",
    "y_hat = model.predict(X_test)\n",
    "precision = precision_score(y_test,y_hat)\n",
    "print('Precision:', precision)\n",
    "run.log('Precision', np.float(precision))\n",
    "\n",
    "#calculate recall\n",
    "recall = recall_score(y_test,y_hat)\n",
    "print('recall:',recall)\n",
    "run.log('Recall',np.float(recall))\n",
    "\n",
    "## Plot the imbalanced data\n",
    "fig = plt.figure(figsize=(12,7)) ## seems it cant change the size of the FacetGrid\n",
    "#sns.catplot(data=fraud_detection,x='Class',kind='count',log=True) ##<-for unknown reason, azure cannot log FacetGrid (shows blank)\n",
    "sns.countplot(data=fraud_detection,x='Class',log=True)\n",
    "# g.fig.suptitle(\"Class Imbalance\",y=1.05,fontsize=15,horizontalalignment='right') #<-also works!\n",
    "plt.title(\"Class Distribution\",y=1.05,fontsize=15,loc='center')\n",
    "plt.xticks([0,1],['False','True'],size=10)\n",
    "plt.xlabel(xlabel='CLASS',size=10) #<-xlabel arg is required\n",
    "run.log_image(name=\"Imbalanced_data\",plot=fig)\n",
    "plt.show()\n",
    "\n",
    "## Plot the balanced data\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "y_bal.value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1],['False','True'],rotation=0,size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.xlabel(\"Class\",size=15)\n",
    "plt.title(\"Class distribution\",loc='center',size=20)\n",
    "run.log_image(name=\"Balanced_data\",plot=fig)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "os.makedirs('outputs',exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/fraud_detection_model_2.pkl') ##<-recall, as this py is run on cloud, you can see this file in the outputs tab in Studio\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Credit_card_fraud_detection_on_azure/fraud_detection_training_w_SMOTE_HYPER.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/fraud_detection_training_w_SMOTE_HYPER.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,precision_score, recall_score, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=1, help='regularization rate')\n",
    "parser.add_argument('--penalty',type=str,dest='penalty',default='none',help='penalty')\n",
    "parser.add_argument(\"--input-data\", type=str, dest='training_dataset_id', help='training dataset')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Set regularization hyperparameters\n",
    "reg = args.reg_rate ## set reg based on what we input in ScriptRunConfig argument parameter\n",
    "pen = args.penalty\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "fraud_detection = run.input_datasets['training_data'].to_pandas_dataframe() ##<-recall, select datasets using name instead of id (see 06)\n",
    "\n",
    "#split data into training set and test set\n",
    "X = fraud_detection.iloc[:, 1:-2]\n",
    "y = fraud_detection.iloc[:, -1]\n",
    "\n",
    "#instantiate SMOTE and transform into balanced dataset\n",
    "sm = SMOTE(random_state=42)\n",
    "X_bal,y_bal = sm.fit_resample(X,y)\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, \n",
    "                                                    test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"lbfgs\",penalty=pen).fit(X_train, y_train)\n",
    "\n",
    "# calculate precision\n",
    "y_hat = model.predict(X_test)\n",
    "precision = precision_score(y_test,y_hat)\n",
    "print('Precision:', precision)\n",
    "run.log('Precision', np.float(precision))\n",
    "\n",
    "#calculate recall\n",
    "recall = recall_score(y_test,y_hat)\n",
    "print('recall:',recall)\n",
    "run.log('Recall',np.float(recall))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "## Plot the imbalanced data\n",
    "fig = plt.figure(figsize=(12,7)) ## seems it cant change the size of the FacetGrid\n",
    "#sns.catplot(data=fraud_detection,x='Class',kind='count',log=True) ##<-for unknown reason, azure cannot log FacetGrid (shows blank)\n",
    "sns.countplot(data=fraud_detection,x='Class',log=True)\n",
    "# g.fig.suptitle(\"Class Imbalance\",y=1.05,fontsize=15,horizontalalignment='right') #<-also works!\n",
    "plt.title(\"Class Distribution\",y=1.05,fontsize=15,loc='center')\n",
    "plt.xticks([0,1],['False','True'],size=10)\n",
    "plt.xlabel(xlabel='CLASS',size=10) #<-xlabel arg is required\n",
    "run.log_image(name=\"Imbalanced_data\",plot=fig)\n",
    "plt.show()\n",
    "\n",
    "## Plot the balanced data\n",
    "fig = plt.figure(figsize=(12,7))\n",
    "y_bal.value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1],['False','True'],rotation=0,size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.xlabel(\"Class\",size=15)\n",
    "plt.title(\"Class distribution\",loc='center',size=20)\n",
    "run.log_image(name=\"Balanced_data\",plot=fig)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "os.makedirs('outputs',exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/fraud_detection_model_2.pkl') ##<-recall, as this py is run on cloud, you can see this file in the outputs tab in Studio\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Credit_card_fraud_detection_on_azure/experiment_env_2.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env_2.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- seaborn\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults  ##<-pip dependencies\n",
    "  - pyarrow           ##<-pip dependencies\n",
    "  - imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_env defined.\n",
      "name: experiment_env\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "- scikit-learn\n",
      "- ipykernel\n",
      "- matplotlib\n",
      "- pandas\n",
      "- seaborn\n",
      "- pip\n",
      "- pip:\n",
      "  - azureml-defaults  ##<-pip dependencies\n",
      "  - pyarrow           ##<-pip dependencies\n",
      "  - imbalanced-learn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "# Create a Python environment for the experiment (from a .yml file)\n",
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env_2.yml\")\n",
    "                                                  ## name of the env (should match that in the yml file?)\n",
    "\n",
    "# Let Azure ML manage dependencies\n",
    "experiment_env.python.user_managed_dependencies = False \n",
    "\n",
    "# Print the environment details\n",
    "print(experiment_env.name, 'defined.')\n",
    "print(experiment_env.python.conda_dependencies.serialize_to_string())\n",
    "                                            ## Serialize conda dependencies object into a string. \n",
    "                                            ## effectively printing the yml content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress.\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"NC-cluster-230102\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    ## ComputeTarget class is for compute cluster creation -->https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-attach-compute-cluster?tabs=python\n",
    "    ## ComputeInstance class if to create compute instance -->https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python\n",
    "    ## but both classes hv ComputeTargetException\n",
    "    ## difference:  ComputeInstance.provisioning_configuration()  vs AmlCompute.provisioning_configuration() for cluster\n",
    "    ## difference2: ComputeInstance.create() vs ComputeTarget.create() for cluster\n",
    "\n",
    "    print('Found existing cluster, use it.')\n",
    "\n",
    "except ComputeTargetException: ##<-this exception will raise if there is no such compute target\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        ## setting the configuration\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "\n",
    "\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11',\n",
       " 'target': 'NC-cluster-230102',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2023-01-02T06:27:15.449063Z',\n",
       " 'endTimeUtc': '2023-01-02T06:28:43.045246Z',\n",
       " 'services': {},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n",
       "  'ContentSnapshotId': '6f636c8a-371c-48f3-aaeb-b9e15d4662f2',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': 'aeb96ed1-60be-48f5-aa46-abca656031b8'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'fraud_detection_training_w_SMOTE.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--regularization',\n",
       "   '0.1',\n",
       "   '--input-data',\n",
       "   'DatasetConsumptionConfig:training_data'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'NC-cluster-230102',\n",
       "  'dataReferences': {},\n",
       "  'data': {'training_data': {'dataLocation': {'dataset': {'id': 'aeb96ed1-60be-48f5-aa46-abca656031b8',\n",
       "      'name': 'credit dataset',\n",
       "      'version': '1'},\n",
       "     'dataPath': None,\n",
       "     'uri': None,\n",
       "     'type': None},\n",
       "    'mechanism': 'Direct',\n",
       "    'environmentVariableName': 'training_data',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False,\n",
       "    'options': None}},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'instanceTypes': [],\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'experiment_env',\n",
       "   'version': 'Autosave_2023-01-02T06:14:57Z_36ba8b55',\n",
       "   'assetId': 'azureml://locations/eastasia/workspaces/19f64139-5fdc-4ca1-bb51-3ea6d5abd27a/environments/experiment_env/versions/Autosave_2023-01-02T06:14:57Z_36ba8b55',\n",
       "   'autoRebuild': True,\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'name': 'experiment_env',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      'scikit-learn',\n",
       "      'ipykernel',\n",
       "      'matplotlib',\n",
       "      'pandas',\n",
       "      'seaborn',\n",
       "      'pip',\n",
       "      {'pip': ['azureml-defaults', 'pyarrow', 'imbalanced-learn']}]},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221101.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'D2',\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'sshPublicKeys': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': []},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=SdH2pXE6LKJ5y4toqmlWgWKpdm2MXMrOyDvRSVkBsvQ%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A18Z&se=2023-01-02T14%3A29%3A18Z&sp=r',\n",
       "  'logs/azureml/dataprep/0/backgroundProcess.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/logs/azureml/dataprep/0/backgroundProcess.log?sv=2019-07-07&sr=b&sig=z6WY3yCGzDKfxyE2inIBtzAmsEQLuqK6v3vzUD%2BE6Os%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A18Z&se=2023-01-02T14%3A29%3A18Z&sp=r',\n",
       "  'logs/azureml/dataprep/0/backgroundProcess_Telemetry.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/logs/azureml/dataprep/0/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=D7c%2Fgev0p%2BIEV3slJCjACCCI5GBOIH4CRQFBy0CQPdw%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A18Z&se=2023-01-02T14%3A29%3A18Z&sp=r',\n",
       "  'logs/azureml/dataprep/0/rslex.log.2023-01-02-06': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/logs/azureml/dataprep/0/rslex.log.2023-01-02-06?sv=2019-07-07&sr=b&sig=ATwrS4hYqQAvHRiKHnFyHDf5q%2F7OTc3Wf0QQ9P8YpeM%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A18Z&se=2023-01-02T14%3A29%3A18Z&sp=r',\n",
       "  'user_logs/std_log.txt': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=FczYIEU7zBu9ItYQ4IXe2VEu0QMfXG7l68T25LOfQzk%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A18Z&se=2023-01-02T14%3A29%3A18Z&sp=r',\n",
       "  'system_logs/cs_capability/cs-capability.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=7xv96r%2FolgH5DeYTwaJAFlyznjEG4XNYfBt7KyS74jM%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A19Z&se=2023-01-02T14%3A29%3A19Z&sp=r',\n",
       "  'system_logs/hosttools_capability/hosttools-capability.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=jnh%2Ft5B%2BpJfUDG%2FcJGIRfLrGLpgOa%2FPziHz4KNblvzE%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A19Z&se=2023-01-02T14%3A29%3A19Z&sp=r',\n",
       "  'system_logs/lifecycler/execution-wrapper.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=XJwKefO2Yoc%2FrJUqQGlTuIACXIkN6phTd0nV%2BMKzodo%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A19Z&se=2023-01-02T14%3A29%3A19Z&sp=r',\n",
       "  'system_logs/lifecycler/lifecycler.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=GNc5LGSD8M%2BQJTHqTIcvrY%2Fsfx76hd4sHcw5FmnDMjo%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A19Z&se=2023-01-02T14%3A29%3A19Z&sp=r',\n",
       "  'system_logs/metrics_capability/metrics-capability.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=4%2BZgOkdRYVd4lItVvCywYNj9QcMLSF3igyyxre3KyLU%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A19Z&se=2023-01-02T14%3A29%3A19Z&sp=r',\n",
       "  'system_logs/snapshot_capability/snapshot-capability.log': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=s0YCe%2BL30eJqTN9e6wATWncNucy%2BiTdaC2%2BFQ5XGK%2FM%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T06%3A19%3A19Z&se=2023-01-02T14%3A29%3A19Z&sp=r'},\n",
       " 'submittedBy': 'King Chor Chan'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "# from azureml-widgets import RunDetails\n",
    "\n",
    "# Get the training dataset\n",
    "credit_ds = ws.datasets.get(\"credit dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='fraud_detection_training_w_SMOTE.py',\n",
    "                                arguments = ['--regularization', 0.1, # Regularizaton rate parameter\n",
    "                                             '--input-data', credit_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                                environment=experiment_env,\n",
    "                                compute_target=cluster_name)\n",
    "                                \n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-fraud-detection-23-01-02'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config)\n",
    "# RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Rate 0.1\n",
      "Precision 0.9730893701767488\n",
      "Recall 0.9152510624348783\n",
      "Imbalanced_data aml://artifactId/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/Imbalanced_data_1672640906.png\n",
      "Balanced_data aml://artifactId/ExperimentRun/dcid.mslearn-train-fraud-detection-23-01-02_1672640094_0e655e11/Balanced_data_1672640907.png\n",
      "\n",
      "\n",
      "Balanced_data_1672640907.png\n",
      "Imbalanced_data_1672640906.png\n",
      "azureml-logs/20_image_build_log.txt\n",
      "logs/azureml/dataprep/0/backgroundProcess.log\n",
      "logs/azureml/dataprep/0/backgroundProcess_Telemetry.log\n",
      "logs/azureml/dataprep/0/rslex.log.2023-01-02-06\n",
      "outputs/fraud_detection_model_2.pkl\n",
      "system_logs/cs_capability/cs-capability.log\n",
      "system_logs/hosttools_capability/hosttools-capability.log\n",
      "system_logs/lifecycler/execution-wrapper.log\n",
      "system_logs/lifecycler/lifecycler.log\n",
      "system_logs/metrics_capability/metrics-capability.log\n",
      "system_logs/snapshot_capability/snapshot-capability.log\n",
      "user_logs/std_log.txt\n"
     ]
    }
   ],
   "source": [
    "# Get logged metrics\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names(): ##<-recall, it shows all the thnigs in the outputs+logs tab\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a',\n",
       " 'target': 'NC-cluster-230102',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2023-01-02T07:31:21.817958Z',\n",
       " 'endTimeUtc': '2023-01-02T07:35:36.601639Z',\n",
       " 'services': {},\n",
       " 'properties': {'primary_metric_config': '{\"name\":\"AUC\",\"goal\":\"maximize\"}',\n",
       "  'resume_from': 'null',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'platform': 'AML',\n",
       "  'ContentSnapshotId': '392a7afe-6652-42db-8210-834e957b154a',\n",
       "  'user_agent': 'python/3.9.7 (macOS-10.16-x86_64-i386-64bit) msrest/0.7.1 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.48.0',\n",
       "  'space_size': '6',\n",
       "  'score': '0.9882588838202568',\n",
       "  'best_child_run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_0',\n",
       "  'best_metric_status': 'Succeeded',\n",
       "  'best_data_container_id': 'dcid.HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_0'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'configuration': None,\n",
       "  'attribution': None,\n",
       "  'telemetryValues': {'amlClientType': 'azureml-sdk-train',\n",
       "   'amlClientModule': '[Scrubbed]',\n",
       "   'amlClientFunction': '[Scrubbed]',\n",
       "   'tenantId': 'c42fedec-8757-4e58-b3d4-1b7e604b3a33',\n",
       "   'amlClientRequestId': '5cff5401-7b87-43d3-b46b-469f26c27c34',\n",
       "   'amlClientSessionId': '39a9ffb9-a937-489e-8fef-1cb5799e4231',\n",
       "   'subscriptionId': '9255a89d-e6f8-47a0-bd21-697de124bc41',\n",
       "   'estimator': 'NoneType',\n",
       "   'samplingMethod': 'GRID',\n",
       "   'terminationPolicy': 'Default',\n",
       "   'primaryMetricGoal': 'maximize',\n",
       "   'maxTotalRuns': 6,\n",
       "   'maxConcurrentRuns': 2,\n",
       "   'maxDurationMinutes': 10080,\n",
       "   'vmSize': None},\n",
       "  'snapshotId': '392a7afe-6652-42db-8210-834e957b154a',\n",
       "  'snapshots': [],\n",
       "  'sourceCodeDataReference': None,\n",
       "  'parentRunId': None,\n",
       "  'dataContainerId': None,\n",
       "  'runType': None,\n",
       "  'displayName': None,\n",
       "  'environmentAssetId': None,\n",
       "  'properties': {},\n",
       "  'tags': {},\n",
       "  'aggregatedArtifactPath': None},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://novchanml1030392394.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=tWChXxuW3GEVw5ptU7zFDP%2B3oFtqSUz%2BiFMNxyAwbdE%3D&skoid=2f973943-e98c-40af-b3d8-80efc153c70c&sktid=c42fedec-8757-4e58-b3d4-1b7e604b3a33&skt=2023-01-02T04%3A43%3A07Z&ske=2023-01-03T12%3A53%3A07Z&sks=b&skv=2019-07-07&st=2023-01-02T07%3A26%3A11Z&se=2023-01-02T15%3A36%3A11Z&sp=r'},\n",
       " 'submittedBy': 'King Chor Chan'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "# from azureml-widgets import RunDetails\n",
    "\n",
    "# Get the training dataset\n",
    "credit_ds = ws.datasets.get(\"credit dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='fraud_detection_training_w_SMOTE_HYPER.py',\n",
    "                                arguments = ['--input-data', credit_ds.as_named_input('training_data')], # Reference to dataset\n",
    "                                environment=experiment_env,\n",
    "                                compute_target=cluster_name)\n",
    "                                \n",
    "# Sample a range of parameter values\n",
    "params = GridParameterSampling(\n",
    "    {\n",
    "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
    "        '--regularization': choice(0.1, 1.0,10),\n",
    "        '--penalty' : choice(['none', 'l2'])\n",
    "    }\n",
    ")                                \n",
    "\n",
    "# Configure hyperdrive settings\n",
    "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
    "                          hyperparameter_sampling=params, \n",
    "                          policy=None, # No early stopping policy\n",
    "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
    "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
    "\n",
    "                                \n",
    "# submit the experiment\n",
    "experiment_name = 'mslearn-train-fraud-detection-23-01-02_hyper_tune'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=hyperdrive)\n",
    "# RunDetails(run).show()\n",
    "run.wait_for_completion()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_0', 'hyperparameters': '{\"--regularization\": 0.1, \"--penalty\": \"l2\"}', 'best_primary_metric': 0.9882588838202568, 'status': 'Completed'}\n",
      "{'run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_5', 'hyperparameters': '{\"--regularization\": 10, \"--penalty\": \"none\"}', 'best_primary_metric': 0.988258806158486, 'status': 'Completed'}\n",
      "{'run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_3', 'hyperparameters': '{\"--regularization\": 1.0, \"--penalty\": \"none\"}', 'best_primary_metric': 0.988258806158486, 'status': 'Completed'}\n",
      "{'run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_1', 'hyperparameters': '{\"--regularization\": 0.1, \"--penalty\": \"none\"}', 'best_primary_metric': 0.988258806158486, 'status': 'Completed'}\n",
      "{'run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_2', 'hyperparameters': '{\"--regularization\": 1.0, \"--penalty\": \"l2\"}', 'best_primary_metric': 0.9882582047952175, 'status': 'Completed'}\n",
      "{'run_id': 'HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_4', 'hyperparameters': '{\"--regularization\": 10, \"--penalty\": \"l2\"}', 'best_primary_metric': 0.9882562563782271, 'status': 'Completed'}\n",
      "Best Run Id:  HD_9cbfbf3b-1b91-48b7-93ef-0db373b4568a_0\n",
      " -AUC: 0.9882588838202568\n",
      " -Arguments: ['--input-data', 'DatasetConsumptionConfig:training_data', '--regularization', '0.1', '--penalty', 'l2']\n"
     ]
    }
   ],
   "source": [
    "for child_run in run.get_children_sorted_by_primary_metric():\n",
    "    print(child_run)\n",
    "\n",
    "# Get the best run, and its metrics and arguments\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print(' -AUC:', best_run_metrics['AUC'])\n",
    "print(' -Arguments:',script_arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb2c41e4cf8a7da65c6999204da30f8ec4f756dfa1b45f06e94fe3440d8e6028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
